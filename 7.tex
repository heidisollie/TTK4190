\section*{Problem 1.7}

\begin{gather*}
    \dot{\tilde \eta} = -\frac{1}{2} \boldsymbol{\tilde \epsilon^\top} \boldsymbol{\tilde \omega} \\
    \boldsymbol{\tilde \omega} = \boldsymbol{\omega - \omega_d}, \boldsymbol{\tilde \epsilon} = \boldsymbol{\epsilon - \epsilon_d}\\
    \boldsymbol{\omega_d} = \mathbf{0}, \boldsymbol{\epsilon_d} = \text{constant}, \eta_d = \text{constant}, \boldsymbol{\tau} = 0 \\
    \boldsymbol{\tau} = -\mathbf{K}_d \boldsymbol{\omega} - k_p \boldsymbol{\tilde \epsilon}
\end{gather*}

\\ \\ Let's consider the Lyapunov function candidate
\begin{equation*}
    V = \frac{1}{2} { \boldsymbol{\tilde \omega}}^\top \mathbf{I}_{CG} \boldsymbol{\tilde \omega} + 2k_p(1 - \tilde \eta)
\end{equation*}
\\ By using the fact that $\mathbf{I}_{CG} = mr^2 \mathbf{I}_3 > 0$ and $\tilde \eta = \cos{\frac{\beta}{2}}$ we know that $\frac{1}{2} { \boldsymbol{\tilde \omega}}^\top \mathbf{I}_{CG} \boldsymbol{\tilde \omega} \geq 0$ and that $\tilde \eta \in [-1,1] \Rightarrow 2k_p(1 - \tilde \eta) \geq 0$ which implies that $V$ is always positive.

\\ $V$ is radially unbounded because it has no upper bound. $\boldsymbol{\tilde \omega} = \boldsymbol{\omega} - \boldsymbol{\omega_d}$ which has no upper bound, especially in the case where $\boldsymbol{\omega_d} = 0$. One could also argue that the first part of the sum would increase much faster than the second part of the sum, making that part negligible. However, since we showed that both are always positive, this is not necessary.



\begin{align*}
 \dot V &= \boldsymbol{\tilde \omega^\top}  \mathbf{I}_{CG} \boldsymbol{\dot{\tilde \omega}} - 2k_p\dot{\tilde \eta} \\
    &=  \boldsymbol{\omega^\top}  \mathbf{I}_{CG}\boldsymbol{\dot{ \omega}} - 2k_p\dot{\tilde \eta}\\
    &=    \boldsymbol{\omega^\top}  \mathbf{I}_{CG}(\mathbf{I}_{CG}^{-1} \boldsymbol{\tau}) - 2k_p(-\frac{1}{2} \boldsymbol{\tilde \epsilon^\top \tilde \omega}) \\
    &=  \boldsymbol{\omega^\top}  \boldsymbol{\tau} - 2k_p(-\frac{1}{2} \boldsymbol{\tilde \epsilon^\top \omega}) \\
    &=  \boldsymbol{\omega^\top}  (-\mathbf{K_d}\boldsymbol{\omega} - k_p \boldsymbol{tilde \epsilon}) - 2k_p(-\frac{1}{2} \boldsymbol{\tilde \epsilon^\top  \omega}) \\
    &= - \boldsymbol{\omega^\top} \mathbf{K_d} \boldsymbol{\omega} - \boldsymbol{\omega^\top} k_p \boldsymbol{\tilde \epsilon} + k_p \boldsymbol{\tilde \epsilon^\top \omega} \\
    &= - \boldsymbol{\omega^\top} \mathbf{K_d} \boldsymbol{\omega} \\
    &= - \boldsymbol{\omega^\top} \m{-k_d && 0 && 0 \\ 0 && -k_d && 0 \\ 0 && 0 && -k_d} \boldsymbol{\omega} \\
    &= -k_d  \boldsymbol{\omega^\top} \boldsymbol{\omega} 
\end{align*}


Barbalat's Lemma allows for the following result. \\
If there exists a uniformly continuous function $V: \mathbb{R}^n \rightarrow \mathbb{R}$ satisfying the following conditions:

\begin{enumerate}  
\item $V(\mathbf{x}) \geq 0$
\item $\dot V(\mathbf{x}) \leq 0$
\item $\dot V(\mathbf{x})$ is uniformly continuous 
\end{enumerate}

Then $\lim_{t \rightarrow \infty} \dot V(\mathbf{x}) = 0$. \\
Note: $\ddot V(\mathbf{x})$ is bounded $\Rightarrow \dot{V}(\mathbf{x})$ is uniformly continuous



\\We showed that (1) is fulfilled above. (2) is obvious, since $k_d > 0$. (3) we will show by showing that $\ddot V(x)$ is bounded.

\\ $\ddot V(x) = -2k_d \omega^\top \dot \omega$. We cannot mathematically show that this function is bounded. However, if we consider the physical aspects of the system, we can assume that the function $V$ does not begin at $\infty$. We also know that $V$ is always positive and $\dot V$ is always negative. This means our function is always sinking, and must stop at 0. Therefore we know $\omega$ will never stray far away from it's initial value and can therefore not diverge to $\infty$. 
Now, since we know $\omega$ is continuous (because this is a physical continuous system), $\dot \omega$ will never be $\pm \infty$. 
Therefore $\ddot V$ must be bounded, meaning $\dot V$ is uniformly continuous and we know $$\lim_{t \rightarrow \infty} \dot V(\mathbf{x}) = -k_d  \boldsymbol{\omega^\top} \boldsymbol{\omega} = 0.$
Since $k_d \neq 0, \boldsymbol{\omega}$ converges to zero.

According to Fossen\cite{bok}, Barbalat's lemma guarantees global convergence, therefore our convergence to the equilibrium point is global.
 
To show asymptotic stability of the system we will use Theorem 4.1 in Nonlinear Systems\cite{bok2}:

\textbf{Theorem 4.1}: Let $x^*$ be an equilibrium point for the system (4.1) and let $V : \mathbb{R}^n \rightarrow \mathbb{R}$ be a continuously differentiable function such that
\begin{enumerate}
    \item $V(\mathbf{0}) = 0, V(\mathbf{x}) > 0, \mathbf{x} \neq 0$
    \item $\dot{V}(\mathbf{x}) < 0, \mathbf{x} \neq 0$
\end{enumerate}
Then $x^*$ is asymptotically stable.

If we can show that the equilibrium point of the system is asymptotically stable, we know that that system is asymptotically stable as our system only has one equilibrium point. 


Let's use 
\begin{equation*}
    V = \frac{1}{2} { \boldsymbol{\tilde \omega}}^\top \mathbf{I}_{CG} \boldsymbol{\tilde \omega} + 2k_p(1 - \tilde \eta)
\end{equation*}
as our function.

$V(\mathbf{0}) = 0$, since $\boldsymbol{\tilde \omega = \omega} = \mathbf{0}$ and $\eta = 1$.\\
$V(\mathbf{x}) > 0, \mathbf{x} \neq 0$ we showed partly by showing that the function is always positive. It is also obvious that when $x \neq 0$ then $V \neq 0$. \\
$ \dot V(\mathbf{x}) = -k_d  \boldsymbol{\omega^\top} \boldsymbol{\omega}, k_d > 0,$ is always $\leq 0$, as we showed earlier. We can also see that the function cannot be zero when $\mathbf{x} \neq 0$. 

Therefore we can conclude that the system is asymptotically stable. 
